{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import keras\n",
    "import keras.layers as nn\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Keras\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        return u.load()\n",
    "    \n",
    "def changeFeatureFormat(total_feature):\n",
    "    changed_feature = []\n",
    "    datum = []\n",
    "    eid = total_feature[0][0]\n",
    "    for feature in total_feature:\n",
    "        if eid != feature[0]:\n",
    "            changed_feature.append(datum)\n",
    "            datum = []\n",
    "            eid = feature[0]\n",
    "        datum.append(feature[1:])\n",
    "    changed_feature.append(datum)\n",
    "    return changed_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollment_df ['enrollment_id', 'username', 'course_id']\n",
      "truth_train_df ['enrollment_id', 'dropout']\n",
      "truth_test_df ['enrollment_id', 'dropout']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/beom/Workspace/DataEngineering/FinalProject/Data\"\n",
    "\n",
    "enrollment_df = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"delimiter\", \",\")\n",
    "        .csv(DATA_PATH + \"/enrollment.csv\")    \n",
    "        .withColumn(\"enrollment_id\", F.col(\"enrollment_id\").cast(\"int\"))\n",
    ")\n",
    "print(\"enrollment_df\", enrollment_df.columns)\n",
    "\n",
    "truth_train_df = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"delimiter\", \",\")\n",
    "        .csv(DATA_PATH + \"/truth_train.csv\")\n",
    "        .select(\n",
    "            F.col(\"eid\").alias(\"enrollment_id\"),\n",
    "            F.col(\"result\").cast(\"boolean\").alias(\"dropout\")\n",
    "        )\n",
    "        .withColumn(\"enrollment_id\", F.col(\"enrollment_id\").cast(\"int\"))\n",
    ")\n",
    "print(\"truth_train_df\", truth_train_df.columns)\n",
    "\n",
    "truth_test_df = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"delimiter\", \",\")\n",
    "        .csv(DATA_PATH + \"/truth_test.csv\")\n",
    "        .select(\n",
    "            F.col(\"eid\").alias(\"enrollment_id\"),\n",
    "            F.col(\"result\").cast(\"boolean\").alias(\"dropout\")\n",
    "        )\n",
    "        .withColumn(\"enrollment_id\", F.col(\"enrollment_id\").cast(\"int\"))\n",
    ")\n",
    "print(\"truth_test_df\", truth_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = load_pickle(DATA_PATH + \"/feature1.pkl\")\n",
    "feature2 = load_pickle(DATA_PATH + \"/feature2.pkl\")\n",
    "feature3 = load_pickle(DATA_PATH + \"/feature3.pkl\")\n",
    "feature4 = load_pickle(DATA_PATH + \"/feature4.pkl\")\n",
    "feature5 = load_pickle(DATA_PATH + \"/feature5.pkl\")\n",
    "feature6 = load_pickle(DATA_PATH + \"/feature6.pkl\")\n",
    "\n",
    "train_feature2 = load_pickle(DATA_PATH + \"/train_feature2.pkl\")\n",
    "train_feature3 = load_pickle(DATA_PATH + \"/train_feature3.pkl\")\n",
    "train_feature4 = load_pickle(DATA_PATH + \"/train_feature4.pkl\")\n",
    "train_feature5 = load_pickle(DATA_PATH + \"/train_feature5.pkl\")\n",
    "\n",
    "train_enrollments = enrollment_df.join(truth_train_df, [\"enrollment_id\"]).collect()\n",
    "test_enrollments = enrollment_df.join(truth_test_df, [\"enrollment_id\"]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.len = len(dataset)\n",
    "        self.x_data = [[r.enrollment_id, r.username, r.course_id] for r in dataset]\n",
    "        self.y_data = torch.Tensor([r.dropout for r in dataset])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        enrollment_id, username, course_id = self.x_data[index]\n",
    "        t1 = torch.zeros(1, 30, 13)\n",
    "        for t in feature1[enrollment_id]:\n",
    "            t1[0][t[0]] = torch.Tensor(list(t[1]))\n",
    "            \n",
    "        t2 = torch.zeros(30, 10)\n",
    "        for t in train_feature2[username]:\n",
    "            t2[t[0]] = torch.Tensor(list(t[1]))\n",
    "        t2 = t2.view(-1)\n",
    "        \n",
    "        t3 = torch.zeros(30, 10)\n",
    "        for t in train_feature3[course_id]:\n",
    "            t3[t[0]] = torch.Tensor(list(t[1]))\n",
    "        t3 = t3.view(-1)\n",
    "        \n",
    "        t4 = torch.Tensor(list(train_feature4[username]))\n",
    "        t5 = torch.Tensor(list(train_feature5[course_id]))\n",
    "        t6 = torch.Tensor(list(feature6[course_id]))\n",
    "            \n",
    "        return t1, torch.cat([t2, t3, t4, t5, t6]), self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "        \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.len = len(dataset)\n",
    "        self.x_data = [[r.enrollment_id, r.username, r.course_id] for r in dataset]\n",
    "        self.y_data = torch.Tensor([r.dropout for r in dataset])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        enrollment_id, username, course_id = self.x_data[index]\n",
    "        t1 = torch.zeros(1, 30, 13)\n",
    "        for t in feature1[enrollment_id]:\n",
    "            t1[0][t[0]] = torch.Tensor(list(t[1]))\n",
    "            \n",
    "        t2 = torch.zeros(30, 10)\n",
    "        for t in feature2[username]:\n",
    "            t2[t[0]] = torch.Tensor(list(t[1]))\n",
    "        t2 = t2.view(-1)\n",
    "        \n",
    "        t3 = torch.zeros(30, 10)\n",
    "        for t in feature3[course_id]:\n",
    "            t3[t[0]] = torch.Tensor(list(t[1]))\n",
    "        t3 = t3.view(-1)\n",
    "        \n",
    "        t4 = torch.Tensor(list(feature4[username]))\n",
    "        t5 = torch.Tensor(list(feature5[course_id]))\n",
    "        t6 = torch.Tensor(list(feature6[course_id]))\n",
    "            \n",
    "        return t1, torch.cat([t2, t3, t4, t5, t6]), self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "\n",
    "train_dataset = TrainDataset(train_enrollments)\n",
    "test_dataset = TestDataset(test_enrollments)\n",
    "\n",
    "batch_size = 100\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_x1 = None\n",
    "train_x2 = None\n",
    "train_y = None\n",
    "\n",
    "for x1, x2, y in train_data_loader:\n",
    "    if train_x1 is None: \n",
    "        train_x1 = x1\n",
    "        train_x2 = x2\n",
    "        train_y = y\n",
    "    else:\n",
    "        train_x1 = torch.cat([train_x1, x1])\n",
    "        train_x2 = torch.cat([train_x2, x2])\n",
    "        train_y = torch.cat([train_y, y])\n",
    "\n",
    "\n",
    "test_x1 = None\n",
    "test_x2 = None\n",
    "test_y = None\n",
    "\n",
    "for x1, x2, y in test_data_loader:\n",
    "    if test_x1 is None: \n",
    "        test_x1 = x1\n",
    "        test_x2 = x2\n",
    "        test_y = y\n",
    "    else:\n",
    "        test_x1 = torch.cat([test_x1, x1])\n",
    "        test_x2 = torch.cat([test_x2, x2])\n",
    "        test_y = torch.cat([test_y, y])\n",
    "        \n",
    "train_x1 = train_x1.data.numpy()\n",
    "train_x2 = train_x2.data.numpy()\n",
    "train_y = train_y.data.numpy()\n",
    "\n",
    "test_x1 = test_x1.data.numpy()\n",
    "test_x2 = test_x2.data.numpy()\n",
    "test_y = test_y.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_net(x):\n",
    "    h1 = nn.AveragePooling2D(pool_size=3, strides=1, padding=\"same\", data_format=\"channels_first\")(x)\n",
    "    h1 = nn.Conv2D(filters=4, kernel_size=1, data_format=\"channels_first\")(h1)\n",
    "    h2 = nn.Conv2D(filters=3, kernel_size=1, data_format=\"channels_first\")(x)\n",
    "    h3 = nn.Conv2D(filters=3, kernel_size=1, data_format=\"channels_first\")(x)\n",
    "    h3 = nn.Conv2D(filters=6, kernel_size=5, padding=\"same\", data_format=\"channels_first\")(h3)\n",
    "    h = nn.Concatenate(axis=1)([h1, h2, h3])\n",
    "    return h\n",
    "\n",
    "def make_model():\n",
    "    input1 = nn.Input(shape=(1, 30, 13))\n",
    "    input2 = nn.Input(shape=(622,))\n",
    "    \n",
    "    h1 = nn.Conv2D(filters=15, kernel_size=3, strides=1, data_format=\"channels_first\")(input1)\n",
    "    h1 = nn.AveragePooling2D(pool_size=2, strides=2, data_format=\"channels_first\")(h1)\n",
    "    h1 = nn.ReLU()(h1)\n",
    "    h1 = inception_net(h1)\n",
    "    h1 = nn.Flatten(data_format=\"channels_first\")(h1)\n",
    "    h1 = nn.Dense(512, activation=\"relu\")(h1)\n",
    "    h1 = nn.Dense(512)(h1)\n",
    "    \n",
    "    h2 = nn.Dense(512, activation=\"relu\")(input2)\n",
    "    h2 = nn.Dense(512)(h2)\n",
    "    \n",
    "    h = nn.Concatenate(axis=1)([h1, h2])\n",
    "    h = nn.Dense(258, activation=\"relu\")(h)\n",
    "    h = nn.Dense(1, activation=\"sigmoid\")(h)\n",
    "    \n",
    "    model = Model(inputs=[input1, input2], outputs=[h])\n",
    "    return model\n",
    "    \n",
    "model = make_model()\n",
    "\n",
    "MODEL_PATH = DATA_PATH + \"/keras_model\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(\n",
    "    MODEL_PATH + \"/{epoch:02d}-{val_loss:.4f}-{val_acc:.4f}-{val_auc:.4f}.hdf5\",\n",
    "    verbose=1,\n",
    "    monitor=\"val_loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90502 samples, validate on 30040 samples\n",
      "Epoch 9/50\n",
      "90502/90502 [==============================] - 258s 3ms/step - loss: 0.3910 - acc: 0.8682 - auc: 0.8402 - val_loss: 0.5698 - val_acc: 0.8467 - val_auc: 0.8340\n",
      "\n",
      "Epoch 00009: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/09-0.5698-0.8467-0.8340.hdf5\n",
      "Epoch 10/50\n",
      "90502/90502 [==============================] - 255s 3ms/step - loss: 0.3667 - acc: 0.8710 - auc: 0.8325 - val_loss: 0.4020 - val_acc: 0.8681 - val_auc: 0.8414\n",
      "\n",
      "Epoch 00010: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/10-0.4020-0.8681-0.8414.hdf5\n",
      "Epoch 11/50\n",
      "90502/90502 [==============================] - 255s 3ms/step - loss: 0.3693 - acc: 0.8703 - auc: 0.8432 - val_loss: 0.7155 - val_acc: 0.8433 - val_auc: 0.8374\n",
      "\n",
      "Epoch 00011: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/11-0.7155-0.8433-0.8374.hdf5\n",
      "Epoch 12/50\n",
      "90502/90502 [==============================] - 255s 3ms/step - loss: 0.3709 - acc: 0.8708 - auc: 0.8353 - val_loss: 0.3878 - val_acc: 0.8711 - val_auc: 0.8387\n",
      "\n",
      "Epoch 00012: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/12-0.3878-0.8711-0.8387.hdf5\n",
      "Epoch 13/50\n",
      "90502/90502 [==============================] - 255s 3ms/step - loss: 0.3707 - acc: 0.8728 - auc: 0.8401 - val_loss: 0.3988 - val_acc: 0.8684 - val_auc: 0.8427\n",
      "\n",
      "Epoch 00013: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/13-0.3988-0.8684-0.8427.hdf5\n",
      "Epoch 14/50\n",
      "90502/90502 [==============================] - 254s 3ms/step - loss: 0.3653 - acc: 0.8732 - auc: 0.8441 - val_loss: 0.3725 - val_acc: 0.8750 - val_auc: 0.8460\n",
      "\n",
      "Epoch 00014: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/14-0.3725-0.8750-0.8460.hdf5\n",
      "Epoch 15/50\n",
      "90502/90502 [==============================] - 254s 3ms/step - loss: 0.3342 - acc: 0.8786 - auc: 0.8477 - val_loss: 0.3941 - val_acc: 0.8672 - val_auc: 0.8496\n",
      "\n",
      "Epoch 00015: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/15-0.3941-0.8672-0.8496.hdf5\n",
      "Epoch 16/50\n",
      "90502/90502 [==============================] - 254s 3ms/step - loss: 0.3134 - acc: 0.8829 - auc: 0.8511 - val_loss: 0.3758 - val_acc: 0.8730 - val_auc: 0.8531\n",
      "\n",
      "Epoch 00016: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/16-0.3758-0.8730-0.8531.hdf5\n",
      "Epoch 17/50\n",
      "90502/90502 [==============================] - 256s 3ms/step - loss: 0.3468 - acc: 0.8766 - auc: 0.8537 - val_loss: 0.4396 - val_acc: 0.8617 - val_auc: 0.8542\n",
      "\n",
      "Epoch 00017: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/17-0.4396-0.8617-0.8542.hdf5\n",
      "Epoch 18/50\n",
      "90502/90502 [==============================] - 259s 3ms/step - loss: 0.3201 - acc: 0.8820 - auc: 0.8548 - val_loss: 0.5734 - val_acc: 0.8475 - val_auc: 0.8543\n",
      "\n",
      "Epoch 00018: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/18-0.5734-0.8475-0.8543.hdf5\n",
      "Epoch 19/50\n",
      "90502/90502 [==============================] - 258s 3ms/step - loss: 0.3083 - acc: 0.8853 - auc: 0.8543 - val_loss: 0.4457 - val_acc: 0.8451 - val_auc: 0.8554\n",
      "\n",
      "Epoch 00019: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/19-0.4457-0.8451-0.8554.hdf5\n",
      "Epoch 20/50\n",
      "90502/90502 [==============================] - 258s 3ms/step - loss: 0.3203 - acc: 0.8835 - auc: 0.8555 - val_loss: 0.5035 - val_acc: 0.8599 - val_auc: 0.8559\n",
      "\n",
      "Epoch 00020: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/20-0.5035-0.8599-0.8559.hdf5\n",
      "Epoch 21/50\n",
      "90502/90502 [==============================] - 258s 3ms/step - loss: 0.3168 - acc: 0.8855 - auc: 0.8561 - val_loss: 0.3508 - val_acc: 0.8763 - val_auc: 0.8573\n",
      "\n",
      "Epoch 00021: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/21-0.3508-0.8763-0.8573.hdf5\n",
      "Epoch 22/50\n",
      "90502/90502 [==============================] - 259s 3ms/step - loss: 0.2985 - acc: 0.8891 - auc: 0.8582 - val_loss: 0.3365 - val_acc: 0.8811 - val_auc: 0.8597\n",
      "\n",
      "Epoch 00022: saving model to /Users/beom/Workspace/DataEngineering/FinalProject/Data/keras_model/22-0.3365-0.8811-0.8597.hdf5\n",
      "Epoch 23/50\n",
      " 2048/90502 [..............................] - ETA: 3:44 - loss: 0.2769 - acc: 0.8955 - auc: 0.8597"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-45d1d2fad9a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_PATH + \"/08-0.3863-0.8677-0.7892.hdf5\")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-5),\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    [train_x1, train_x2], train_y, \n",
    "    validation_data=([test_x1, test_x2], test_y),\n",
    "    batch_size=256, \n",
    "    shuffle=True, \n",
    "    verbose=1, \n",
    "    epochs=50, \n",
    "    initial_epoch=8,\n",
    "    callbacks=[cb_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_roc_curve(model, x1, x2, y):\n",
    "    scores = model.predict([x1, x2])\n",
    "    pred = scores.reshape(-1)\n",
    "    true = y.reshape(-1)\n",
    "    \n",
    "    _pred = np.array([1 if p >= 0.5 else 0 for p in pred])\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true, pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    acc = metrics.accuracy_score(true, _pred)\n",
    "    diff = np.sum(np.abs(true - _pred))\n",
    "    \n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "    print(auc, acc, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8854838533881986 0.8810585885486019 3573.0\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_PATH + \"/22-0.3365-0.8811-0.8597.hdf5\")\n",
    "make_roc_curve(model, test_x1, test_x2, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321767065427619 0.9026430355130274 8811.0\n"
     ]
    }
   ],
   "source": [
    "make_roc_curve(model, train_x1, train_x2, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1576195\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "    \n",
    "def make_pytorch_model():\n",
    "    \n",
    "    class Flatten(nn.Module):\n",
    "        def forward(self, x):\n",
    "            N, C, H, W = x.size()\n",
    "            return x.view(N, -1)\n",
    "\n",
    "\n",
    "    class InceptionA(nn.Module):\n",
    "        def __init__(self, in_channels):\n",
    "            super(InceptionA, self).__init__()\n",
    "            self.avg_pooling = torch.nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "            self.conv1 = torch.nn.Conv2d(in_channels, 4, kernel_size=1)\n",
    "            self.conv2 = torch.nn.Conv2d(in_channels, 3, kernel_size=1)\n",
    "            self.conv3 = torch.nn.Conv2d(in_channels, 3, kernel_size=1)\n",
    "            self.conv4 = torch.nn.Conv2d(3, 6, kernel_size=5, padding=2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h1 = self.avg_pooling(x)\n",
    "            h1 = self.conv1(h1)\n",
    "            h2 = self.conv2(x)\n",
    "            h3 = self.conv3(x)\n",
    "            h3 = self.conv4(h3)\n",
    "            h = torch.cat([h1, h2, h3], 1)\n",
    "            return h\n",
    "\n",
    "\n",
    "    class CNNModel(nn.Module):\n",
    "        def __init__(self, output_size):\n",
    "            super(CNNModel, self).__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Conv2d(1, 15, kernel_size=3, stride=1),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                InceptionA(15),\n",
    "                Flatten(),\n",
    "                nn.Linear(910, output_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(output_size, output_size),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "\n",
    "\n",
    "    class MLPModel(nn.Module):\n",
    "        def __init__(self, output_size):\n",
    "            super(MLPModel, self).__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(622, output_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(output_size, output_size),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "\n",
    "\n",
    "    class Model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Model, self).__init__()\n",
    "            self.cnn_network = CNNModel(512)\n",
    "            self.mlp_network = MLPModel(512)\n",
    "            self.concated_network = nn.Sequential(\n",
    "                nn.Linear(1024, 258),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(258, 1),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x1, x2 = x\n",
    "            h1 = self.cnn_network(x1)\n",
    "            h2 = self.mlp_network(x2)\n",
    "            h = torch.cat([h1, h2], 1)\n",
    "            h = self.concated_network(h)\n",
    "            return h\n",
    "\n",
    "    pytorch_model = Model()\n",
    "\n",
    "    load_data = torch.load(DATA_PATH + \"/model/epoch-67\")\n",
    "    pytorch_model.load_state_dict(load_data[\"model_state_dict\"])\n",
    "\n",
    "    def get_n_params(model):\n",
    "        pp=0\n",
    "        for p in list(model.parameters()):\n",
    "            nn=1\n",
    "            for s in list(p.size()):\n",
    "                nn = nn*s\n",
    "            pp += nn\n",
    "        return pp\n",
    "\n",
    "    print(get_n_params(pytorch_model))\n",
    "    return pytorch_model\n",
    "    \n",
    "pytorch_model = make_pytorch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_81 (InputLayer)           (None, 1, 30, 13)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cnn_network.network.0 (Conv2D)  (None, 15, 28, 11)   150         input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_65 (AveragePo (None, 15, 14, 5)    0           cnn_network.network.0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 15, 14, 5)    0           average_pooling2d_65[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_66 (AveragePo (None, 15, 14, 5)    0           re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cnn_network.network.3.conv3 (Co (None, 3, 14, 5)     48          re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cnn_network.network.3.conv1 (Co (None, 4, 14, 5)     64          average_pooling2d_66[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cnn_network.network.3.conv2 (Co (None, 3, 14, 5)     48          re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cnn_network.network.3.conv4 (Co (None, 6, 14, 5)     456         cnn_network.network.3.conv3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 13, 14, 5)    0           cnn_network.network.3.conv1[0][0]\n",
      "                                                                 cnn_network.network.3.conv2[0][0]\n",
      "                                                                 cnn_network.network.3.conv4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 910)          0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_82 (InputLayer)           (None, 622)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cnn_network.network.5 (Dense)   (None, 512)          466432      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_network.network.0 (Dense)   (None, 512)          318976      input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cnn_network.network.7 (Dense)   (None, 512)          262656      cnn_network.network.5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "mlp_network.network.2 (Dense)   (None, 512)          262656      mlp_network.network.0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 1024)         0           cnn_network.network.7[0][0]      \n",
      "                                                                 mlp_network.network.2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concated_network.0 (Dense)      (None, 258)          264450      concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concated_network.2 (Dense)      (None, 1)            259         concated_network.0[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,576,195\n",
      "Trainable params: 1,576,195\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import keras\n",
    "import keras.layers as nn\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def make_keras_model():\n",
    "\n",
    "    def inception_net(x):\n",
    "        h1 = nn.AveragePooling2D(pool_size=3, strides=1, padding=\"same\", data_format=\"channels_first\")(x)\n",
    "        h1 = nn.Conv2D(filters=4, kernel_size=1, data_format=\"channels_first\", name=\"cnn_network.network.3.conv1\")(h1)\n",
    "        h2 = nn.Conv2D(filters=3, kernel_size=1, data_format=\"channels_first\", name=\"cnn_network.network.3.conv2\")(x)\n",
    "        h3 = nn.Conv2D(filters=3, kernel_size=1, data_format=\"channels_first\", name=\"cnn_network.network.3.conv3\")(x)\n",
    "        h3 = nn.Conv2D(filters=6, kernel_size=5, padding=\"same\", data_format=\"channels_first\", name=\"cnn_network.network.3.conv4\")(h3)\n",
    "        h = nn.Concatenate(axis=1)([h1, h2, h3])\n",
    "        return h\n",
    "\n",
    "    def make_model():\n",
    "        input1 = nn.Input(shape=(1, 30, 13))\n",
    "        input2 = nn.Input(shape=(622,))\n",
    "\n",
    "        h1 = nn.Conv2D(filters=15, kernel_size=3, strides=1, data_format=\"channels_first\", name=\"cnn_network.network.0\")(input1)\n",
    "        h1 = nn.AveragePooling2D(pool_size=2, strides=2, data_format=\"channels_first\")(h1)\n",
    "        h1 = nn.ReLU()(h1)\n",
    "        h1 = inception_net(h1)\n",
    "        h1 = nn.Flatten(data_format=\"channels_first\")(h1)\n",
    "        h1 = nn.Dense(512, activation=\"relu\", name=\"cnn_network.network.5\")(h1)\n",
    "        h1 = nn.Dense(512, name=\"cnn_network.network.7\")(h1)\n",
    "\n",
    "        h2 = nn.Dense(512, activation=\"relu\", name=\"mlp_network.network.0\")(input2)\n",
    "        h2 = nn.Dense(512, name=\"mlp_network.network.2\")(h2)\n",
    "\n",
    "        h = nn.Concatenate(axis=1)([h1, h2])\n",
    "        h = nn.Dense(258, activation=\"relu\", name=\"concated_network.0\")(h)\n",
    "        h = nn.Dense(1, activation=\"sigmoid\", name=\"concated_network.2\")(h)\n",
    "\n",
    "        model = Model(inputs=[input1, input2], outputs=[h])\n",
    "        return model\n",
    "\n",
    "    keras_model = make_model()\n",
    "    keras_model.summary()\n",
    "    return keras_model\n",
    "\n",
    "model = make_keras_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import keras\n",
    "import torch\n",
    "\n",
    "VAR_AFFIX = ':0' if keras.backend.backend() == 'tensorflow' else ''\n",
    "\n",
    "KERAS_GAMMA_KEY = 'gamma' + VAR_AFFIX\n",
    "KERAS_KERNEL_KEY = 'kernel' + VAR_AFFIX\n",
    "KERAS_ALPHA_KEY = 'alpha' + VAR_AFFIX\n",
    "KERAS_BIAS_KEY = 'bias' + VAR_AFFIX\n",
    "KERAS_BETA_KEY = 'beta' + VAR_AFFIX\n",
    "KERAS_MOVING_MEAN_KEY = 'moving_mean' + VAR_AFFIX\n",
    "KERAS_MOVING_VARIANCE_KEY = 'moving_variance' + VAR_AFFIX\n",
    "KERAS_EPSILON = 1e-3\n",
    "PYTORCH_EPSILON = 1e-5\n",
    "\n",
    "\n",
    "_WEIGHT_KEYS = ['kernel', 'beta', 'alpha']\n",
    "_WEIGHT_KEYS += [key+':0' for key in _WEIGHT_KEYS]\n",
    "\n",
    "\n",
    "def state_dict_layer_names(state_dict):\n",
    "    layer_names = [\".\".join(k.split('.')[:-1]) for k in state_dict.keys()]\n",
    "    return list(OrderedDict.fromkeys(layer_names))\n",
    "\n",
    "\n",
    "def _contains_weights(keras_h5_layer):\n",
    "    for key in _WEIGHT_KEYS:\n",
    "        if key in keras_h5_layer:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def dig_to_params(keras_h5_layer):\n",
    "    while not _contains_weights(keras_h5_layer):\n",
    "        keras_h5_layer = keras_h5_layer[list(keras_h5_layer.keys())[0]]\n",
    "\n",
    "    return keras_h5_layer\n",
    "\n",
    "def check_for_missing_layers(keras_names, pytorch_layer_names, verbose):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Layer names in PyTorch state_dict\", pytorch_layer_names)\n",
    "        print(\"Layer names in Keras HDF5\", keras_names)\n",
    "\n",
    "    if not all(x in keras_names for x in pytorch_layer_names):\n",
    "        missing_layers = list(set(pytorch_layer_names) - set(keras_names))\n",
    "        raise Exception(\"Missing layer(s) in Keras HDF5 that are present\" +\n",
    "                        \" in state_dict: {}\".format(missing_layers))\n",
    "\n",
    "\n",
    "def keras_to_pytorch(keras_model, pytorch_model,\n",
    "                     flip_filters=None, verbose=True):\n",
    "\n",
    "    # If not specifically set, determine whether to flip filters automatically\n",
    "    # for the right backend.\n",
    "    if flip_filters is None:\n",
    "        flip_filters = not keras.backend.backend() == 'tensorflow'\n",
    "\n",
    "    keras_model.save('temp.h5')\n",
    "    input_state_dict = pytorch_model.state_dict()\n",
    "    pytorch_layer_names = state_dict_layer_names(input_state_dict)\n",
    "\n",
    "    with h5py.File('temp.h5', 'r') as f:\n",
    "        model_weights = f['model_weights']\n",
    "        layer_names = list(map(str, model_weights.keys()))\n",
    "        check_for_missing_layers(layer_names, pytorch_layer_names, verbose)\n",
    "        state_dict = OrderedDict()\n",
    "\n",
    "        for layer in pytorch_layer_names:\n",
    "\n",
    "            params = dig_to_params(model_weights[layer])\n",
    "\n",
    "            weight_key = layer + '.weight'\n",
    "            bias_key = layer + '.bias'\n",
    "            running_mean_key = layer + '.running_mean'\n",
    "            running_var_key = layer + '.running_var'\n",
    "\n",
    "            # Load weights (or other learned parameters)\n",
    "            if weight_key in input_state_dict:\n",
    "                if KERAS_GAMMA_KEY in params:\n",
    "                    weights = params[KERAS_GAMMA_KEY][:]\n",
    "                elif KERAS_KERNEL_KEY in params:\n",
    "                    weights = params[KERAS_KERNEL_KEY][:]\n",
    "                else:\n",
    "                    weights = np.squeeze(params[KERAS_ALPHA_KEY][:])\n",
    "\n",
    "                weights = convert_weights(weights,\n",
    "                                          to_keras=True,\n",
    "                                          flip_filters=flip_filters)\n",
    "\n",
    "                state_dict[weight_key] = torch.from_numpy(weights)\n",
    "\n",
    "            # Load bias\n",
    "            if bias_key in input_state_dict:\n",
    "                if running_var_key in input_state_dict:\n",
    "                    bias = params[KERAS_BETA_KEY][:]\n",
    "                else:\n",
    "                    bias = params[KERAS_BIAS_KEY][:]\n",
    "                state_dict[bias_key] = torch.from_numpy(\n",
    "                    bias.transpose())\n",
    "\n",
    "            # Load batch normalization running mean\n",
    "            if running_mean_key in input_state_dict:\n",
    "                running_mean = params[KERAS_MOVING_MEAN_KEY][:]\n",
    "                state_dict[running_mean_key] = torch.from_numpy(\n",
    "                    running_mean.transpose())\n",
    "\n",
    "            # Load batch normalization running variance\n",
    "            if running_var_key in input_state_dict:\n",
    "                running_var = params[KERAS_MOVING_VARIANCE_KEY][:]\n",
    "                # account for difference in epsilon used\n",
    "                running_var += KERAS_EPSILON - PYTORCH_EPSILON\n",
    "                state_dict[running_var_key] = torch.from_numpy(\n",
    "                    running_var.transpose())\n",
    "\n",
    "    pytorch_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def pytorch_to_keras(pytorch_model, keras_model,\n",
    "                     flip_filters=False, flip_channels=None, verbose=True):\n",
    "\n",
    "    if flip_channels is None:\n",
    "        flip_channels = not keras.backend.backend() == 'tensorflow'\n",
    "\n",
    "    keras_model.save('temp.h5')\n",
    "    input_state_dict = pytorch_model.state_dict()\n",
    "    pytorch_layer_names = state_dict_layer_names(input_state_dict)\n",
    "\n",
    "    with h5py.File('temp.h5', 'a') as f:\n",
    "        model_weights = f['model_weights']\n",
    "        target_layer_names = list(map(str, model_weights.keys()))\n",
    "        check_for_missing_layers(\n",
    "            target_layer_names,\n",
    "            pytorch_layer_names,\n",
    "            verbose)\n",
    "\n",
    "        for layer in pytorch_layer_names:\n",
    "\n",
    "            params = dig_to_params(model_weights[layer])\n",
    "\n",
    "            weight_key = layer + '.weight'\n",
    "            bias_key = layer + '.bias'\n",
    "            running_mean_key = layer + '.running_mean'\n",
    "            running_var_key = layer + '.running_var'\n",
    "\n",
    "            # Load weights (or other learned parameters)\n",
    "            if weight_key in input_state_dict:\n",
    "                weights = input_state_dict[weight_key].numpy()\n",
    "                weights = convert_weights(weights,\n",
    "                                          to_keras=False,\n",
    "                                          flip_filters=flip_filters,\n",
    "                                          flip_channels=flip_channels)\n",
    "\n",
    "                if KERAS_GAMMA_KEY in params:\n",
    "                    params[KERAS_GAMMA_KEY][:] = weights\n",
    "                elif KERAS_KERNEL_KEY in params:\n",
    "                    params[KERAS_KERNEL_KEY][:] = weights\n",
    "                else:\n",
    "                    weights = weights.reshape(params[KERAS_ALPHA_KEY][:].shape)\n",
    "                    params[KERAS_ALPHA_KEY][:] = weights\n",
    "\n",
    "            # Load bias\n",
    "            if bias_key in input_state_dict:\n",
    "                bias = input_state_dict[bias_key].numpy()\n",
    "                if running_var_key in input_state_dict:\n",
    "                    params[KERAS_BETA_KEY][:] = bias\n",
    "                else:\n",
    "                    params[KERAS_BIAS_KEY][:] = bias\n",
    "\n",
    "            # Load batch normalization running mean\n",
    "            if running_mean_key in input_state_dict:\n",
    "                running_mean = input_state_dict[running_mean_key].numpy()\n",
    "                params[KERAS_MOVING_MEAN_KEY][:] = running_mean\n",
    "\n",
    "            # Load batch normalization running variance\n",
    "            if running_var_key in input_state_dict:\n",
    "                running_var = input_state_dict[running_var_key].numpy()\n",
    "                # account for difference in epsilon used\n",
    "                running_var += PYTORCH_EPSILON - KERAS_EPSILON\n",
    "                params[KERAS_MOVING_VARIANCE_KEY][:] = running_var\n",
    "\n",
    "    # pytorch_model.load_state_dict(state_dict)\n",
    "    keras_model.load_weights('temp.h5')\n",
    "\n",
    "\n",
    "def convert_weights(weights, to_keras, flip_filters, flip_channels=False):\n",
    "\n",
    "    if len(weights.shape) == 3:  # 1D conv\n",
    "        weights = weights.transpose()\n",
    "\n",
    "        if flip_channels:\n",
    "            weights = weights[::-1]\n",
    "\n",
    "        if flip_filters:\n",
    "            weights = weights[..., ::-1].copy()\n",
    "\n",
    "    if len(weights.shape) == 4:  # 2D conv\n",
    "        if to_keras:  # D1 D2 F F\n",
    "            weights = weights.transpose(3, 2, 0, 1)\n",
    "        else:\n",
    "            weights = weights.transpose(2, 3, 1, 0)\n",
    "\n",
    "        if flip_channels:\n",
    "            weights = weights[::-1, ::-1]\n",
    "        if flip_filters:\n",
    "            weights = weights[..., ::-1, ::-1].copy()\n",
    "\n",
    "    elif len(weights.shape) == 5:  # 3D conv\n",
    "        if to_keras:  # D1 D2 D3 F F\n",
    "            weights = weights.transpose(4, 3, 0, 1, 2)\n",
    "        else:\n",
    "            weights = weights.transpose(2, 3, 4, 1, 0)\n",
    "\n",
    "        if flip_channels:\n",
    "            weights = weights[::-1, ::-1, ::-1]\n",
    "\n",
    "        if flip_filters:\n",
    "            weights = weights[..., ::-1, ::-1, ::-1].copy()\n",
    "    else:\n",
    "        weights = weights.transpose()\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer names in PyTorch state_dict ['cnn_network.network.0', 'cnn_network.network.3.conv1', 'cnn_network.network.3.conv2', 'cnn_network.network.3.conv3', 'cnn_network.network.3.conv4', 'cnn_network.network.5', 'cnn_network.network.7', 'mlp_network.network.0', 'mlp_network.network.2', 'concated_network.0', 'concated_network.2']\n",
      "Layer names in Keras HDF5 ['average_pooling2d_65', 'average_pooling2d_66', 'cnn_network.network.0', 'cnn_network.network.3.conv1', 'cnn_network.network.3.conv2', 'cnn_network.network.3.conv3', 'cnn_network.network.3.conv4', 'cnn_network.network.5', 'cnn_network.network.7', 'concated_network.0', 'concated_network.2', 'concatenate_52', 'concatenate_53', 'flatten_20', 'input_81', 'input_82', 'mlp_network.network.0', 'mlp_network.network.2', 're_lu_10']\n"
     ]
    }
   ],
   "source": [
    "pytorch_to_keras(pytorch_model, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
